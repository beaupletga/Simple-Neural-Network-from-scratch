{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(x,y,derivative=False,name='mse'):\n",
    "    if name=='mse':\n",
    "        return mse(x,y,derivative)\n",
    "    if name=='mae':\n",
    "        return mae(x,y,derivative)\n",
    "\n",
    "def mse(x,y,derivative=False):\n",
    "    if not derivative:\n",
    "        return 0.5*np.mean(x-y)**2\n",
    "    else:\n",
    "        return (x-y)\n",
    "    \n",
    "def mae(x,y,derivative=False):\n",
    "    if not derivative:\n",
    "        return np.abs(x-y)\n",
    "    else:\n",
    "        return (x-y)/(((x-y)**2)**0.5)\n",
    "\n",
    "def show_error(error_list):\n",
    "    plt.clf()\n",
    "    plt.plot(error_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_initializer(size,name='random_normal'):\n",
    "    if name=='random_normal':\n",
    "        return np.random.normal(size=size)\n",
    "    if name=='random_uniform':\n",
    "        return np.random.uniform(size=size)\n",
    "    if name=='random':\n",
    "        return 2*np.random.random(size=size)-1\n",
    "    if name=='zeros':\n",
    "        return np.zeros(size)\n",
    "    if name=='ones':\n",
    "        return np.ones(size)\n",
    "    if name=='lecun_uniform':\n",
    "        limit=np.sqrt(3 / size[0])\n",
    "        return np.random.uniform(low=-limit,high=limit,size=size)\n",
    "    if name=='TruncatedNormal':\n",
    "        return np.random.normal(loc=0,scale=0.5,size=size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x,is_derivative=False,name='elu'):\n",
    "    if name=='relu':\n",
    "        return relu(x,is_derivative)\n",
    "    if name=='sigmoid':\n",
    "        return sigmoid(x,is_derivative)\n",
    "    if name=='tanh':\n",
    "        return tanh(x,is_derivative)\n",
    "    if name=='elu':\n",
    "        return elu(x,is_derivative)\n",
    "    \n",
    "def sigmoid(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if is_derivative:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))    \n",
    "\n",
    "def relu(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        return np.maximum(x,0)\n",
    "    else:\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=0\n",
    "        return x\n",
    "def tanh(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        return np.tanh(x)\n",
    "    else:\n",
    "        return 1-x**2\n",
    "    \n",
    "def elu(a,is_derivative=False):\n",
    "    alpha=1\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        x[x<0]=alpha*(np.exp(x[x<0])-1)\n",
    "        return x\n",
    "    else:\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=x[x<0]+alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop(a,drop_name='dropout',ratio=0.25):\n",
    "    if drop_name==None:\n",
    "        return a\n",
    "    if drop_name=='dropout':\n",
    "        return dropout(a,ratio)\n",
    "    elif dop_name==\"dc\":\n",
    "        return drop_connect(a,ratio)\n",
    "\n",
    "# we set randomly connections to zeros\n",
    "def drop_connect(a,ratio=0.05):\n",
    "    x=copy.copy(a)\n",
    "    rand=np.random.random(list(x.shape))\n",
    "    x[rand<ratio]=0\n",
    "    return x\n",
    "\n",
    "# we set to zeros one of the column of the weights matrix\n",
    "def dropout(a,ratio):\n",
    "    x=copy.copy(a)\n",
    "    rand=np.random.rand(x.shape[1])\n",
    "    x[:,rand<ratio]=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00202377]\n",
      " [ 0.99748664]\n",
      " [ 0.99699808]\n",
      " [ 0.0033685 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOfzNzNqQw9/MrA05/M3M2tD/B+Q0cE0I/MyCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76c086c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def neural_network(x,y,epochs,hidden=[2,3],bias=True,gamma=0.1,drop_name=None,loss_name='mse',\n",
    "                  weights_init_name='random_normal',lr_decay=0):\n",
    "    length=len(hidden)\n",
    "    error_list=[]\n",
    "    \n",
    "#     initialize the weigths for consistant matrix multiplications\n",
    "    weights_list=[weights_initializer((x.shape[1],hidden[0]),weights_init_name)]\n",
    "    for i in range(1,length):\n",
    "        weights_list.append(weights_initializer((hidden[i-1],hidden[i]),weights_init_name))\n",
    "    weights_list.append(weights_initializer((hidden[-1],y.shape[1]),weights_init_name))\n",
    "    \n",
    "#     add bias \n",
    "#     there are as many bias as hidden_layer+1\n",
    "    if bias:\n",
    "        bias=2*np.random.rand(length+1)-1\n",
    "    else:\n",
    "        bias=np.zeros(length+1)\n",
    "        \n",
    "    for iter in range(epochs):\n",
    "        gamma*=1/(1+lr_decay*epochs)\n",
    "#         list containing the output of each layer\n",
    "#         len(out_list)=len(hidden)+1\n",
    "        out_list=[]\n",
    "        for j in range(0,length+1):\n",
    "#             if first layer the first element is x\n",
    "            if j==0:\n",
    "                out_list.append(f(x.dot(drop(weights_list[0],drop_name))+bias[j]))\n",
    "#             else this is the result of the previous layer\n",
    "            else:\n",
    "#                we don t apply dropout to the last layer because we might annul one of the outputs neurons   \n",
    "                if j!=length:\n",
    "                    out_list.append(f(out_list[-1].dot(drop(weights_list[j],drop_name))+bias[j]))\n",
    "                else:\n",
    "                    out_list.append(f(out_list[-1].dot(weights_list[j])+bias[j]))\n",
    "#         print out_list\n",
    "#         compute the error of the algorithm (for the error curve)        \n",
    "        error = np.mean(loss(out_list[-1],y,loss_name))\n",
    "        \n",
    "#         compute the first two partial derivative a the thumb rule\n",
    "        delta_list=[loss(out_list[-1],y,True,loss_name)*f(out_list[-1],True)]\n",
    "#         print out_list\n",
    "        for j in range(length,-1,-1):\n",
    "#             print out_list\n",
    "#             we use the previous result the previous delta\n",
    "#             we then multiply it by the weights of the next layer\n",
    "            delta_list.append(delta_list[-1].dot(weights_list[j].T)*f(out_list[j-1],True))\n",
    "        \n",
    "#         update the weights between each layer \n",
    "#         there are (lengths+1) weights matrix\n",
    "        for j in range(0,length+1):\n",
    "#             if this is the first weights matrix, then the input isn t the result of the previous layer but x (input data)\n",
    "            if j==0:\n",
    "                weights_list[j] -= gamma* x.T.dot(delta_list[length])\n",
    "#             if this is not the first weights matrix, then the input is the result of the previous layer\n",
    "            else:\n",
    "                weights_list[j] -= gamma* out_list[j-1].T.dot(delta_list[length-j])\n",
    "        \n",
    "        for j in range(length,-1,-1):\n",
    "            bias[j] -= gamma * np.mean(delta_list[j+1])\n",
    "#         we append each error to a list to see the evolution of the error\n",
    "        error_list.append(error)\n",
    "    print out_list[-1]\n",
    "#     show the error with pyplot\n",
    "    show_error(error_list)\n",
    "\n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "\n",
    "neural_network(x,y,hidden=[4,2],epochs=1000,gamma=0.1,bias=True,drop_name=None,loss_name='mse',\n",
    "               weights_init_name='lecun_uniform',lr_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
