{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2,  2,  3])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([-1,2,3])\n",
    "\n",
    "a[a<0]=a[a<0]*2\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x,is_derivative=False,name='elu'):\n",
    "    if name=='relu':\n",
    "        return relu(x,is_derivative)\n",
    "    if name=='sigmoid':\n",
    "        return sigmoid(x,is_derivative)\n",
    "    if name=='tanh':\n",
    "        return tanh(x,is_derivative)\n",
    "    if name=='elu':\n",
    "        return elu(x,is_derivative)\n",
    "    \n",
    "def sigmoid(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if is_derivative:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))    \n",
    "\n",
    "def relu(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        return np.maximum(x,0)\n",
    "    else:\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=0\n",
    "        return x\n",
    "def tanh(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        return np.tanh(x)\n",
    "    else:\n",
    "        return 1-x**2\n",
    "    \n",
    "def elu(a,is_derivative=False):\n",
    "    alpha=1\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        x[x<0]=alpha*(np.exp(x[x<0])-1)\n",
    "        return x\n",
    "    else:\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=x[x<0]+alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mse(x,y):\n",
    "    return 0.5*np.mean(x-y)**2\n",
    "        \n",
    "\n",
    "def neural_network(x,y,hidden=[2]):\n",
    "    error_list=[]\n",
    "    w1=2*np.random.rand(x.shape[1],hidden[0])-1\n",
    "    w2=2*np.random.rand(hidden[0],y.shape[1])-1\n",
    "    bias=2*np.random.rand(len(hidden)+1)-1\n",
    "    gamma = 0.01\n",
    "    for iter in range(100000):\n",
    "        out1 = f(x.dot(w1)+bias[0])\n",
    "        out2 = f(out1.dot(w2)+bias[1])\n",
    "        error = mse(out2,y)\n",
    "        \n",
    "        delta2 = (out2-y)*f(out2,True)\n",
    "        \n",
    "        error1 = delta2.dot(w2.T)\n",
    "        delta1 = error1 * f(out1,True)\n",
    "        \n",
    "        \n",
    "        w2 -= gamma* out1.T.dot(delta2)\n",
    "        bias[1] -= gamma * np.mean(delta2)\n",
    "        bias[0] -= gamma * np.mean(delta1)\n",
    "        w1 -= gamma* x.T.dot(delta1)\n",
    "\n",
    "        error_list.append(error)\n",
    "    plt.clf()\n",
    "    plt.plot(error_list)\n",
    "    plt.show()\n",
    "    print out2\n",
    "    return w1,w2\n",
    "\n",
    "# def neural_network(x,y,hidden=[2]):\n",
    "#     error_list=[]\n",
    "#     w1=2*np.random.rand(x.shape[1],1)-1\n",
    "#     for iter in range(100):\n",
    "#         out=f(x.dot(w1))\n",
    "#         error=mse(out,y)\n",
    "#         w1 -= 1 * x.T.dot(((out-y)*out*(1-out)))\n",
    "#         error_list.append(error)\n",
    "#     plt.clf()\n",
    "#     plt.plot(error_list)\n",
    "#     plt.show()\n",
    "#     print out\n",
    "#     return w1\n",
    "                                        \n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "\n",
    "# w1,w2=neural_network(x,y,[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.21603748e-05]\n",
      " [  1.00107879e+00]\n",
      " [  9.98927657e-01]\n",
      " [  1.10959995e-04]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEuLQNzNLyP8HOnIAqz5bD6MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa238358050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_error(error_list):\n",
    "    plt.clf()\n",
    "    plt.plot(error_list)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def neural_network(x,y,epochs,hidden=[2,3],bias=True,gamma=0.1):\n",
    "    length=len(hidden)\n",
    "    error_list=[]\n",
    "    \n",
    "#     initialize the weigths for consistant matrix multiplications\n",
    "    weights_list=[2*np.random.rand(x.shape[1],hidden[0])-1]\n",
    "    for i in range(1,length):\n",
    "        weights_list.append(2*np.random.rand(hidden[i-1],hidden[i])-1)\n",
    "    weights_list.append(2*np.random.rand(hidden[-1],y.shape[1])-1)\n",
    "    \n",
    "#     add bias \n",
    "#     there are as many bias as hidden_layer+1\n",
    "    if bias:\n",
    "        bias=2*np.random.rand(length+1)-1\n",
    "    else:\n",
    "        bias=np.zeros(length+1)\n",
    "        \n",
    "#     learning rate\n",
    "    for iter in range(epochs):\n",
    "#         list containing the output of each layer\n",
    "#         len(out_list)=len(hidden)+1\n",
    "        out_list=[]\n",
    "        for j in range(0,length+1):\n",
    "#             if first layer the first element is x\n",
    "            if j==0:\n",
    "                out_list.append(f(x.dot(weights_list[0])+bias[j]))\n",
    "#             else this is the result of the previous layer\n",
    "            else:\n",
    "                out_list.append(f(out_list[-1].dot(weights_list[j])+bias[j]))\n",
    "#         print out_list\n",
    "#         compute the error of the algorithm (for the error curve)        \n",
    "        error = mse(out_list[-1],y)\n",
    "        \n",
    "#         compute the first two partial derivative a the thumb rule\n",
    "        delta_list=[(out_list[-1]-y)*f(out_list[-1],True)]\n",
    "#         print out_list\n",
    "        for j in range(length,-1,-1):\n",
    "#             print out_list\n",
    "#             we use the previous result the previous delta\n",
    "#             we then multiply it by the weights of the next layer\n",
    "            delta_list.append(delta_list[-1].dot(weights_list[j].T)*f(out_list[j-1],True))\n",
    "        \n",
    "#         update the weights between each layer \n",
    "#         there are (lengths+1) weights matrix\n",
    "        for j in range(0,length+1):\n",
    "#             if this is the first weights matrix, then the input isn t the result of the previous layer but x (input data)\n",
    "            if j==0:\n",
    "                weights_list[j] -= gamma* x.T.dot(delta_list[length])\n",
    "#             if this is not the first weights matrix, then the input is the result of the previous layer\n",
    "            else:\n",
    "                weights_list[j] -= gamma* out_list[j-1].T.dot(delta_list[length-j])\n",
    "        \n",
    "        for j in range(length,-1,-1):\n",
    "            bias[j] -= gamma * np.mean(delta_list[j+1])\n",
    "#         we append each error to a list to see the evolution of the error\n",
    "        error_list.append(error)\n",
    "    print out_list[-1]\n",
    "#     show the error with pyplot\n",
    "    show_error(error_list)\n",
    "\n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "\n",
    "neural_network(x,y,hidden=[4,2],epochs=100,gamma=0.1,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
