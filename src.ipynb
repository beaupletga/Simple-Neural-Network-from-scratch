{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03124756],\n",
       "       [ 0.22957403],\n",
       "       [ 0.7046275 ],\n",
       "       [ 0.08756251],\n",
       "       [ 0.03058948],\n",
       "       [ 0.35713493],\n",
       "       [ 0.58978199],\n",
       "       [ 0.05222273],\n",
       "       [ 0.06566367],\n",
       "       [ 0.04350119]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(x,y):\n",
    "    return 0.5*np.mean(x-y)**2\n",
    "\n",
    "def show_error(error_list):\n",
    "    plt.clf()\n",
    "    plt.plot(error_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x,is_derivative=False,name='elu'):\n",
    "    if name=='relu':\n",
    "        return relu(x,is_derivative)\n",
    "    if name=='sigmoid':\n",
    "        return sigmoid(x,is_derivative)\n",
    "    if name=='tanh':\n",
    "        return tanh(x,is_derivative)\n",
    "    if name=='elu':\n",
    "        return elu(x,is_derivative)\n",
    "    \n",
    "def sigmoid(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if is_derivative:\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))    \n",
    "\n",
    "def relu(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        return np.maximum(x,0)\n",
    "    else:\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=0\n",
    "        return x\n",
    "def tanh(a,is_derivative=False):\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        return np.tanh(x)\n",
    "    else:\n",
    "        return 1-x**2\n",
    "    \n",
    "def elu(a,is_derivative=False):\n",
    "    alpha=1\n",
    "    x=copy.copy(a)\n",
    "    if not is_derivative:\n",
    "        x[x<0]=alpha*(np.exp(x[x<0])-1)\n",
    "        return x\n",
    "    else:\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=x[x<0]+alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_connect(a,drop_connect=True,ratio=0.1):\n",
    "    x=copy.copy(a)\n",
    "    if drop_connect:\n",
    "        rand=np.random.random(list(x.shape))\n",
    "        x[rand<ratio]=0\n",
    "        return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxuCXpMIY/JJUmP8PDMLMF4yEeZUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdfb5e848d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def neural_network(x,y,epochs,hidden=[2,3],bias=True,gamma=0.1,dc=True):\n",
    "    length=len(hidden)\n",
    "    error_list=[]\n",
    "    \n",
    "#     initialize the weigths for consistant matrix multiplications\n",
    "    weights_list=[2*np.random.rand(x.shape[1],hidden[0])-1]\n",
    "    for i in range(1,length):\n",
    "        weights_list.append(2*np.random.rand(hidden[i-1],hidden[i])-1)\n",
    "    weights_list.append(2*np.random.rand(hidden[-1],y.shape[1])-1)\n",
    "    \n",
    "#     add bias \n",
    "#     there are as many bias as hidden_layer+1\n",
    "    if bias:\n",
    "        bias=2*np.random.rand(length+1)-1\n",
    "    else:\n",
    "        bias=np.zeros(length+1)\n",
    "        \n",
    "#     learning rate\n",
    "    for iter in range(epochs):\n",
    "#         list containing the output of each layer\n",
    "#         len(out_list)=len(hidden)+1\n",
    "        out_list=[]\n",
    "        for j in range(0,length+1):\n",
    "#             if first layer the first element is x\n",
    "            if j==0:\n",
    "                out_list.append(f(x.dot(drop_connect(weights_list[0],dc))+bias[j]))\n",
    "#             else this is the result of the previous layer\n",
    "            else:\n",
    "                out_list.append(f(out_list[-1].dot(drop_connect(weights_list[j],dc))+bias[j]))\n",
    "#         print out_list\n",
    "#         compute the error of the algorithm (for the error curve)        \n",
    "        error = mse(out_list[-1],y)\n",
    "        \n",
    "#         compute the first two partial derivative a the thumb rule\n",
    "        delta_list=[(out_list[-1]-y)*f(out_list[-1],True)]\n",
    "#         print out_list\n",
    "        for j in range(length,-1,-1):\n",
    "#             print out_list\n",
    "#             we use the previous result the previous delta\n",
    "#             we then multiply it by the weights of the next layer\n",
    "            delta_list.append(delta_list[-1].dot(weights_list[j].T)*f(out_list[j-1],True))\n",
    "        \n",
    "#         update the weights between each layer \n",
    "#         there are (lengths+1) weights matrix\n",
    "        for j in range(0,length+1):\n",
    "#             if this is the first weights matrix, then the input isn t the result of the previous layer but x (input data)\n",
    "            if j==0:\n",
    "                weights_list[j] -= gamma* x.T.dot(delta_list[length])\n",
    "#             if this is not the first weights matrix, then the input is the result of the previous layer\n",
    "            else:\n",
    "                weights_list[j] -= gamma* out_list[j-1].T.dot(delta_list[length-j])\n",
    "        \n",
    "        for j in range(length,-1,-1):\n",
    "            bias[j] -= gamma * np.mean(delta_list[j+1])\n",
    "#         we append each error to a list to see the evolution of the error\n",
    "        error_list.append(error)\n",
    "    print out_list[-1]\n",
    "#     show the error with pyplot\n",
    "    show_error(error_list)\n",
    "\n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "\n",
    "neural_network(x,y,hidden=[4,2],epochs=10000,gamma=0.1,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
